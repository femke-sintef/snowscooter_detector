##############################################################
################## MODEL BUILDING SETTINGS ###################
##############################################################

######################
# METRICS MONITORING #
######################
search_type: tpe
# Experiment number for MLflow / Note that it is not possible
# to have the same experiment name multiple times


# Path for storing Pytorch lightning logs
PATH_LIGHTNING_METRICS: "./training/lightning_training/lightning_logs"

########################
# Audio files settings # 
########################

LENGTH_SEGMENTS: [3, 5] # in seconds
SAMPLE_RATE: [44100, 16000, 8000]
FFT_HOP_LENGTH: [160, 100, 200, 561] # original was 561
FFT_N_FFT: 2048  # original was 2048 - cannot change when relying on pretrained!
FFT_WIN_LENGTH: 1654 # original was 1654 - cannot change when relying on pretrained!         
FFT_WINDOW: 'blackmanharris' # original was 'blackmanharris'               
#################
# PATH SETTINGS #
#################

# Connection string if connecting to a remote server
# String in the form "ssh://user:password@host", can also be set to False
# if data is stored locally
CONNECTION_STRING: False # OR "ssh://user:password@host" 

# Path to the audio dataset used for training and validation
PATH_TRAIN_VAL_DATASET: /data/phd_femke/soundsolution/Ben_backup/Model_training_data/
# PATH_TRAIN_VAL_DATASET: /media/storage_10TB/soundsolution/Ben_backup/Model_training_data/
# Path to the audio component of the test dataset 
TEST_PATH: '/data/phd_femke/soundsolution/test_dataset/audio'
# TEST_PATH: '/media/storage_10TB/soundsolution/test_dataset/audio'
# Path to the labels of the test dataset
TEST_DF_PATH: '/data/phd_femke/soundsolution/test_dataset/labels'
# TEST_DF_PATH: '/media/storage_10TB/soundsolution/test_dataset/labels'

# Label file
LABEL_FILE: '/home/femkegb/Documents/snowscooter_detector/assets/label_correspondance.json' # If not in a docker container, please specify the full path

###########################
# Adding background noise #
###########################

# True or False
# True if you want to add other soundscape data to the audio file
IS_BG_NOISE: False

# True or False
# True if you want to add short noises to the audio file
IS_SHORT_NOISE: False

# If IS_BG_NOISE is True add the path to the folder containing
# the background noises
# !! PyfileSystem does not apply here so bg noise should be stored where the model is trained !!
PATH_BG_NOISE: "/media/storage_10TB/soundsolution/Ben_backup/Model_training_data/Norwegian_soundscape/"

# If IS_BG_NOISE is True add the path to the folder containing
# the background noises
# !! PyfileSystem does not apply here so bg noise should be stored where the model is trained !!
PATH_SHORT_NOISE: "/Data/Noise_background/short_noises"

# Probability of adding short noises and background noises
P_SHORT_NOISE: 0.0 #"tune.uniform(0,1)"
P_BG_NOISE: 0.0 #"tune.uniform(0,1)"

#####################
# TRAINING SETTINGS #
#####################

# fraction of the data to use for validation
PROP_TRAINING: 0.8 

# batch size used // DECREASE IF SHARED MEMORY PROBLEM
BATCH_SIZE: 32 #"tune.choice([16,32,64])"

# number of epochs to run, due to stopping rule this number just needs to be big
N_EPOCHS: 99

# number of epochs since last improvement before stopping training
STOPPING_RULE_PATIENCE: 10

# number of workers to use for data generation, change to 1 for debugging 
NUM_WORKERS: 1

# On what hardware to train the model. Options include: cpu, gpu or tpu
ACCELERATOR: "gpu" 

# Pin memory for the dataloader
PIN_MEMORY: True

# Learning rate to use. NOTE that if using ray.tune you can change to tune.loguniform
LEARNING_RATE: [-3.0, 1.0] #"tune.loguniform(0.00001, 0.1)"

# Number of output neurons for the model
NUM_TARGET_CLASSES: 2

#####################
# RAY TUNE SETTINGS #
#####################

# Name of the ray experiment
NAME_EXPERIMENT: "ray_logs"

# Number of CPU available for each trial
N_CPU_PER_TRIAL: 1

# Number of GPU for each trial / NOTE THAT IN ITS CURRENT SETTINGS
# RAY TUNE USES ONE GPU FOR THE HEAD NODE, HAVE A LEAST 2 GPUS!!!
N_GPU_PER_TRIAL: 1

# Number of trials to do (ONLY IF RANDOM ALGORITHM)
N_SAMPLING: 50

# If Bayesian search:
# RANDOM_SEARCH_STEPS: 20


# Ray tune saves some temp files in some folders that require root access
# It is possible to change the directory to avoid permission problems:
# For storing the ray tune results
# LOCAL_DIR: "." 

#######################
# TRANSFORMS SETTINGS #
#######################

# Regarding the choice of the augmentation see the post on StackExchange:
# https://bioacoustics.stackexchange.com/questions/98/data-augmentation-strategies-for-bioacoustics-machine-learning

# Parameters for the addition of Gaussian noise
GAUSSIAN_MIN_AMPLITUDE: 0.001
GAUSSIAN_MAX_AMPLITUDE: 0.015
GAUSSIAN_P: [0,1] # "tune.uniform(0,1)" # 0.5

# Parameters for SevenBandParametricEQ: 
# modifications to the frequency equalisation (this is similar to slightly 
# changing the response characteristics of your mic)
P_SEVENBANDPARAMETRICEQ: [0,1] #"tune.uniform(0,1)" # 0.5

# Time shifting
P_SHIFT: [0,1] #"tune.uniform(0,1)" # 0.5

# Parameters for AirAbsorption:
# emulating the effects of distance by adding a bit of low-pass filtering, 
# and/or some echo/reverb using an impulse response.
P_AIR_ABSORPTION: [0,1] #"tune.uniform(0,1)" # 0.5

# Time masking and frequency masking -- these don't have a very obvious interpretation but 
# are a kind of "dropout" of frequencies or time regions, and seem to help.
P_TIME_MASK: [0,1] #"tune.uniform(0,1)" # 0.5
P_FREQ_MASK: [0,1] #"tune.uniform(0,1)" # 0.5

hyperopt_param: # settings needed for a bayesian optimization search. Will be ignored if search_type is set to 'full_grid'
  max_evals: 100 # amount of models to be trained
  uniform_keys: [[GAUSSIAN_P], [P_SEVENBANDPARAMETRICEQ], [P_SHIFT],[P_AIR_ABSORPTION],[P_TIME_MASK], [P_FREQ_MASK]] # keys (separate with comma for nested keys) of values that should be picked from a uniform distributed floats. Define range as [lower_limit, higher_limit]
  lognormal_keys: [[LEARNING_RATE]] # keys (spearate with comma for nested keys) of values that should be picked from a lognormal distribution (floats). Define range as [mu, sigma]
  randint_keys: [] # keys (separate with comma for nested keys) of values that should be picked from a uniforly distributed integers. Define range as [lower_limit, higher_limit] or [lower_limit, higher_limit, limit_multiplication_factor]

